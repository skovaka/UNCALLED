#!/usr/bin/env python

# MIT License
#
# Copyright (c) 2018 Sam Kovaka <skovaka@gmail.com>
#
# Permission is hereby granted, free of charge, to any person obtaining a copy
# of this software and associated documentation files (the "Software"), to deal
# in the Software without restriction, including without limitation the rights
# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
# copies of the Software, and to permit persons to whom the Software is
# furnished to do so, subject to the following conditions:
#
# The above copyright notice and this permission notice shall be included in all
# copies or substantial portions of the Software.
#
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
# SOFTWARE.

from uncalled import mapping, index, pafstats, minknow_client, params
import numpy as np
import sys                         
import os
import argparse
import time
import re
import time
import subprocess
import traceback

MAX_SLEEP = 0.01

class ArgFormat(argparse.ArgumentDefaultsHelpFormatter):
    pass

def add_bwa_opt(p):
    p.add_argument("-x", "--bwa-prefix", required=True, type=str, help="BWA prefix to mapping to. Must be processed by \"uncalled index\".")
    p.add_argument("-p", "--index-preset", default="default", type=str, help="Mapping mode")

def add_index_opts(p):
    p.add_argument("-i", "--ref-fasta", required=True, type=str, help="FASTA file used to build BWA index")
    p.add_argument("-s", "--max-sample-dist", default=100, type=int, help="Maximum average sampling distance between reference self-alignments.")
    p.add_argument("--min-samples", default=50000, type=int, help="Minimum number of self-alignments to produce (approximate, due to deterministically random start locations)")
    p.add_argument("-k", "--kmer-len", default=5, type=int, help="Model k-mer length")
    p.add_argument("-1", "--matchpr1", default=0.6334, type=float, help="Minimum event match probability")
    p.add_argument("-2", "--matchpr2", default=0.9838, type=float, help="Maximum event match probability")
    p.add_argument("-f", "--pathlen-percentile", default=0.05, type=float, help="")
    p.add_argument("-m", "--max-replen", default=100, type=int, help="")
    p.add_argument("--probs", default=None, type=str, help="Find parameters with specified target probabilites (comma separated)")
    p.add_argument("--speeds", default=None, type=str, help="Find parameters with specified speed coefficents (comma separated)")

def add_ru_opts(p):
    #TODO: selectively enrich or deplete refs in index
    p.add_argument("-c", "--max-chunks", default=10, type=int, help="Will give up on a read after this many chunks have been processed. Only has effect when --unblock is set")
    p.add_argument("--chunk-size", required=False, type=float, default=1, help="Length of chunks in seconds")

    modes = p.add_mutually_exclusive_group(required=True)
    modes.add_argument("-D", "--deplete", action='store_const', const=mapping.RealtimeMode.DEPLETE, dest='realtime_mode', help="Will eject reads that align to index")
    modes.add_argument("-E", "--enrich", action='store_const',  const=mapping.RealtimeMode.ENRICH, dest='realtime_mode', help="Will eject reads that don't align to index")

    active = p.add_mutually_exclusive_group()
    active.add_argument("--full", action='store_const', const=mapping.ActiveChs.FULL, dest='active_chs', help="Will monitor all pores if set (default)")
    active.add_argument("--even", action='store_const', const=mapping.ActiveChs.EVEN, dest='active_chs', help="Will only monitor even pores if set")
    active.add_argument("--odd", action='store_const', const=mapping.ActiveChs.ODD, dest='active_chs', help="Will only monitor odd pores if set")


def add_realtime_opts(p):
    p.add_argument('--host', default='127.0.0.1', help='MinKNOW server host.')
    p.add_argument('--port', type=int, default=8000, help='MinKNOW server port.')
    p.add_argument('--duration', type=float, default=None, help='Duration to map real-time run in hours. Should be slightly longer than specified runtime to add wiggle room.')

def add_list_ports_opts(p):
    p.add_argument('--log-dir', default='/var/log/MinKNOW', help='Directory to find MinKNOW log files')

def add_fast5_opts(p):
    p.add_argument("-i", "--fast5-list", required=True, type=str, help="Reads to mapping. Can be a directory which will be recursively searched for all files with the \".fast5\" extension, a text file containing one fast5 filename per line, or a comma-separated list of fast5 file names.")
    p.add_argument("-f", "--fast5-filter", required=False, default="", type=str, help="Only map reads listed in this file")
    p.add_argument("-n", "--max-reads", type=int, default=0, help="Maximum number of reads to map")

def add_map_opts(p):
    p.add_argument("-t", "--threads", default=1, type=int, help="Number of threads to use for mapping")
    p.add_argument("--num-channels", default=512, type=int, help="Number of channels used in sequencing. If provided will use unique mapper for each channel. Useful for streaming normalization simulation.")
    p.add_argument("-e", "--max-events", default=30000, type=int, help="Will give up on a read after this many events have been processed")

def get_parser():
    parser = argparse.ArgumentParser(description="Rapidly maps raw nanopore signal to DNA references")
    sp = parser.add_subparsers(dest="subcmd")

    index_parser = sp.add_parser("index", help="Calculates reference-specific parameters needed to map to a given a BWA-index.")#, formatter_class=ArgFormat)
    add_bwa_opt(index_parser)
    add_index_opts(index_parser)

    map_parser = sp.add_parser("map", help="Map fast5 files to a BWA index that has been processed by \"uncalled index\"")#,formatter_class=ArgFormat)
    add_bwa_opt(map_parser)
    add_fast5_opts(map_parser)
    add_map_opts(map_parser)

    rt_parser = sp.add_parser("realtime", help="Perform real-time targeted sequencing")#,formatter_class=ArgFormat)
    add_bwa_opt(rt_parser)
    add_map_opts(rt_parser)
    add_ru_opts(rt_parser)
    add_realtime_opts(rt_parser)

    ps_parser = sp.add_parser("pafstats", help="Computes speed and accuracy of UNCALLED mappings. Given an UNCALLED PAF file, will compute mean/median BP mapped per second, number of BP required to map each read, and total number of milliseconds to map each read. Can also optionally compute accuracy with respect to reference alignments, for example output by minimap2.")
    pafstats.add_opts(ps_parser)

    lp_parser = sp.add_parser("list-ports", help="List the port of all MinION devices detected in the current MinKNOW session")#,formatter_class=ArgFormat)
    add_list_ports_opts(lp_parser)

    return parser

def load_args(args, conf):
    conf.kmer_model = params.MODEL_FNAME

    for a, v in vars(args).items():
        if v == None:
            #sys.stderr.write("%s IS NONE\n" % a)
            continue

        if (not a.startswith("_")):
            if hasattr(conf, a):
                #sys.stderr.write("SET\t%s\t%s\n" % (a, str(v)))
                setattr(conf, a, v)
            else:
                sys.stderr.write("%s\t%s\n" % (a, str(v)))

def index_cmd(args):
    sys.stderr.write("Initializing parameter search\n")
    p = index.IndexParameterizer(args)

    p.add_preset("default", tgt_speed=115)

    if args.probs != None:
        for tgt in args.probs.split(","):
            sys.stderr.write("Writing 'prob_%s' parameters\n" % tgt)
            try:
                p.add_preset("prob_%s" % tgt, tgt_prob=float(tgt))
            except Exception as e:
                sys.stderr.write("Failed to add 'prob_%s'\n" % tgt)

    if args.speeds != None:
        for tgt in args.speeds.split(","):
            sys.stderr.write("Writing 'speed_%s' parameters\n" % tgt)
            try:
                p.add_preset("speed_%s" % tgt, tgt_speed=float(tgt))
            except:
                sys.stderr.write("Failed to add 'speed_%s'\n" % tgt)

    p.write()

    sys.stderr.write("Done\n")

def load_fast5s(arg):
    fast5_list = list()
    if os.path.isdir(arg):
        for root, dirs, files in os.walk(arg):
            for fname in files:
                if not fname.startswith("#") and fname.endswith("fast5"):
                    fast5_list.append(os.path.abspath(os.path.join(root, fname)))

    elif arg.endswith("fast5"):
        for fname in arg.split(","):
            fast5_list.append(os.path.abspath(fname))

    else:
        fast5_list = [os.path.abspath(l.strip()) for l in open(arg)]
    return fast5_list

def assert_exists(fname):
    if not os.path.exists(fname):
        sys.stderr.write("Error: '%s' does not exist\n" % fname)
        sys.exit(1)

def map_cmd(args):
    conf = mapping.Conf(params.CONF_DEFAULTS)
    load_args(args, conf)

    assert_exists(params.MODEL_FNAME)
    assert_exists(conf.bwa_prefix + ".bwt")
    assert_exists(conf.bwa_prefix + ".uncl")
    assert_exists(conf.fast5_list)

    for fname in open(conf.fast5_list):
        assert_exists(fname.strip())
    if len(conf.fast5_filter) > 0:
        assert_exists(conf.fast5_filter)

    sys.stderr.write("Loading fast5_list\n")
    sys.stderr.flush()

    mapper = mapping.Fast5Pool(conf)

    sys.stderr.flush()

    sys.stderr.write("Mapping\n")
    sys.stderr.flush()

    n = 0

    try:
        while not mapper.all_finished() and (not conf.max_reads or n <= conf.max_reads):
            t0 = time.time()
            for p in mapper.update():
                p.print_paf()
                n += 1
                if conf.max_reads and n > conf.max_reads:
                    break
            dt = time.time() - t0;
            if dt < MAX_SLEEP:
                time.sleep(MAX_SLEEP - dt);
            #time.sleep(0.01)
    except KeyboardInterrupt:
        pass

    mapper.stop_all()
    while not mapper.all_finished():
        time.sleep(MAX_SLEEP)

    for p in mapper.update():
        p.print_paf()
        sys.stdout.flush()

def realtime_cmd(args):

    if not minknow_client.ru_loaded:
        sys.stderr.write("Error: read_until module not installed. Please install \"read_until_api\" submodule.\n")
        sys.exit(1)

    conf = mapping.Conf(params.CONF_DEFAULTS)
    load_args(args, conf)

    assert_exists(params.MODEL_FNAME)
    assert_exists(conf.bwa_prefix + ".bwt")
    assert_exists(conf.bwa_prefix + ".uncl")

    pool = None
    client = None

    try:
        client = minknow_client.Client(conf.host, conf.port, conf.chunk_size)

        if not client.run():
            sys.exit(1)

        deplete = conf.realtime_mode == mapping.RealtimeMode.DEPLETE
        even = conf.active_chs == mapping.ActiveChs.EVEN #TODO: do within mapper

        cal = client.device.rpc.device.get_calibration(first_channel=1, last_channel=512)
        raw_type = str(client.signal_dtype)

        pool = mapping.ChunkPool(conf)

        chunk_times = [time.time() for c in range(conf.num_channels)]
        unblocked = [None for c in range(conf.num_channels)]

        client.log("Processing reads")

        if conf.duration == None or conf.duration == 0:
            end_time = float("inf")
        else:
            end_time = conf.duration*60*60

        while client.is_running:
            t0 = time.time()

            for ch, nm, paf in pool.update():
                t = time.time()-chunk_times[ch-1]
                if paf.is_ended():
                    paf.set_float(mapping.Paf.Tag.ENDED, t)
                    client.stop_receiving_read(ch, nm)

                elif (paf.is_mapped() and deplete) or not (paf.is_mapped() or deplete):

                    if client.should_eject():
                        paf.set_float(mapping.Paf.Tag.EJECT, t)
                        client.unblock_read(ch, nm)
                        unblocked[ch-1] = nm
                    else:
                        paf.set_float(mapping.Paf.Tag.IN_SCAN, t)
                        client.stop_receiving_read(ch, nm)

                else:
                    paf.set_float(mapping.Paf.Tag.KEEP, t)
                    client.stop_receiving_read(ch, nm)

                paf.print_paf()

            read_batch = client.get_read_chunks(batch_size=client.queue_length)

            for channel, read in read_batch:
                if even and channel % 2 == 1:
                    client.stop_receiving_read(channel, read.number)
                else:
                    if unblocked[channel-1] == read.number:
                        sys.stdout.write("# recieved chunk from %s after unblocking\n" % read.id)
                        continue

                    chunk_times[channel-1] = time.time()
                    pool.add_chunk(mapping.Chunk(read.id, 
                                                 channel, 
                                                 read.number,
                                                 read.chunk_start_sample,
                                                 raw_type,
                                                 read.raw_data))
                #last_time = time.time()

            if client.get_runtime() >= end_time:
                client.reset()
                client = None
                break

            dt = time.time() - t0;
            if dt < MAX_SLEEP:
                time.sleep(MAX_SLEEP - dt);

    except KeyboardInterrupt:
        sys.stderr.write("Keyboard interrupt\n")

    except Exception as e:
        sys.stderr.write(traceback.format_exc())

    #client.log("Finished")

    if client != None:
        client.reset()

    if pool != None:
        pool.stop_all()

def list_ports_cmd(args):
    log_re = re.compile("^([0-9\-]+ [0-9:]+).+ :.+instance_started.+")
    port_re = re.compile("grpc_port = (\d+)")
    device_re = re.compile("(device_id|instance) = ([^\s,]+)")

    fnames = os.listdir(args.log_dir)
    log_fnames = list(sorted( (f for f in fnames if f.startswith("mk_manager_svc")) ))
    latest_log = os.path.join(args.log_dir, log_fnames[-1])

    for line in open(latest_log):
        lm = log_re.match(line)
        if not lm: continue
        pm = port_re.search(line)
        dm = device_re.search(line)

        if pm is None or dm is None:
            sys.stderr.write("Error: failed to parse \"%s\"\n" % line.strip())
            continue

        timestamp = lm.group(1)
        port = pm.group(1)
        device = dm.group(2)

        sys.stdout.write("%s (%s): %s\n" % (device, timestamp, port))



if __name__ == "__main__":
    
    parser = get_parser()
    args = parser.parse_args()

    if args.subcmd == "index":
        index_cmd(args)
    elif args.subcmd == "map":
        map_cmd(args)
    elif args.subcmd == "realtime":
        realtime_cmd(args)
    elif args.subcmd == "list-ports":
        list_ports_cmd(args)
    elif args.subcmd == "pafstats":
        pafstats.run(args)
    else:
        parser.print_help()
        
